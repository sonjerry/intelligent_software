{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNngp8OY3Hvneb2EG5kmXYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonjerry/intelligent_software/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8LuQZkEMPWuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46df909-72c4-4540-b68f-cda09767dcfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "red: [9.326533472631127e-06, -0.02476814016699791, -0.002384250983595848, -0.028791459277272224, -0.021199282258749008]...\n",
            "1536\n",
            "blue: [0.005474964156746864, -0.007486246060580015, 0.005678507499396801, -0.03110414557158947, -0.01965053379535675]...\n",
            "1536\n",
            "yellow: [0.007661858107894659, -0.024910997599363327, 0.004491548519581556, -0.02860249951481819, -0.01958620548248291]...\n",
            "1536\n",
            "green: [0.01546180434525013, -0.010975971817970276, 0.025183379650115967, -0.02092933841049671, -0.005648194346576929]...\n",
            "1536\n",
            "violet: [-0.006727131083607674, -0.018318135291337967, 0.0036361967213451862, -0.00567674869671464, -0.021194979548454285]...\n",
            "1536\n",
            "cyan: [0.021550633013248444, -0.014010688289999962, 0.008289773017168045, -0.02929886430501938, -0.016149088740348816]...\n",
            "1536\n",
            "black: [-0.015103082172572613, -0.031215764582157135, 0.00877943355590105, -0.03691864386200905, -0.01613996922969818]...\n",
            "1536\n",
            "white: [0.006292110309004784, -0.02457117661833763, 0.0002028137823799625, -0.014848269522190094, -0.0052642603404819965]...\n",
            "1536\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"\"\n",
        "\n",
        "# Function to get embeddings for a list of texts using OpenAI Embeddings API\n",
        "def get_embeddings(texts):\n",
        "    response = openai.Embedding.create(\n",
        "        input=texts,\n",
        "        model=\"text-embedding-ada-002\"  # 0.28 버전에서 사용 가능한 임베딩 모델\n",
        "    )\n",
        "    return [item['embedding'] for item in response['data']]\n",
        "\n",
        "\n",
        "# List of color words to embed\n",
        "color_words = [\"red\", \"blue\", \"yellow\", \"green\", \"violet\", \"cyan\", \"black\", \"white\"]\n",
        "\n",
        "# Get embeddings for the color words\n",
        "color_embeddings = get_embeddings(color_words)\n",
        "\n",
        "# Print the embeddings for each color word\n",
        "for word, embedding in zip(color_words, color_embeddings):\n",
        "    print(f\"{word}: {embedding[:5]}...\")\n",
        "    print(len(embedding))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Set your OpenAI API key\n",
        "OPENAI_API_KEY=\"\"\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "\n",
        "def generate_image(prompt):\n",
        "    response = openai.Image.create(\n",
        "        prompt=prompt,\n",
        "        n=1,                # Number of images to generate\n",
        "        size=\"1024x1024\"    # Size of the generated image\n",
        "    )\n",
        "    image_url = response['data'][0]['url']\n",
        "    return image_url\n",
        "\n",
        "\n",
        "def save_image(image_url, filename):\n",
        "    response = requests.get(image_url)\n",
        "    image = Image.open(BytesIO(response.content))\n",
        "    image.save(filename)\n",
        "\n",
        "\n",
        "# Example prompt\n",
        "prompt = \"a dog that contorl airplane\"\n",
        "\n",
        "# Generate image\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Image URL: {image_url}\")\n",
        "\n",
        "# Save image to file\n",
        "save_image(image_url, \"generated_image.png\")\n",
        "print(\"Image saved as generated_image.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-eZgerWfLo5",
        "outputId": "f3e13e51-6f27-495e-821c-e14268de0ab8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-lx7f5xs2yk84ixlmDbfDaiRT/user-bOzt0bXwYPBrHx8cp1FnW43g/img-JYawdZgOQ8KsWKHckHlu0QT6.png?st=2025-12-01T09%3A29%3A38Z&se=2025-12-01T11%3A29%3A38Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=b2c0e1c0-cf97-4e19-8986-8073905d5723&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-12-01T10%3A29%3A38Z&ske=2025-12-02T10%3A29%3A38Z&sks=b&skv=2024-08-04&sig=EbZ0C5TnQ1/89Mo2NNHwf8h1%2BJcE5LgJfNNKpxe7oFg%3D\n",
            "Image saved as generated_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "# Function to transcribe audio using OpenAI Audio API\n",
        "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\", temperature=0.1, language=None, prompt=None):\n",
        "  with open(file_path, \"rb\") as audio_file:\n",
        "    response = openai.Audio.transcribe(\n",
        "      file=audio_file,\n",
        "      model=model,\n",
        "      response_format=response_format,\n",
        "      temperature=temperature,\n",
        "      language=language,\n",
        "      prompt=prompt\n",
        "    )\n",
        "  return response\n",
        "# Example file path\n",
        "file_path = '/content/Dracula.mp3'\n",
        "\n",
        "# Transcribe the audio file\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4iggl0qtYY6",
        "outputId": "82eafe7a-00bc-4f05-b555-4b7f8695968a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response:\n",
            "{\n",
            "  \"text\": \"Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse, the candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders, searching for some precious grail. We are the embers that glow in the winter, the diamonds in the vine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be points of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds. When the great battle commences, surely the light will prevail. We will break down his defenses, he will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be points of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds.\",\n",
            "  \"usage\": {\n",
            "    \"type\": \"duration\",\n",
            "    \"seconds\": 116\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2zRWAIvglmi",
        "outputId": "021de15f-ab97-4c6b-f431-90ce60e5e941"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.12/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from openai==0.28) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->openai==0.28) (2025.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->openai==0.28) (1.22.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28) (4.15.0)\n"
          ]
        }
      ]
    }
  ]
}